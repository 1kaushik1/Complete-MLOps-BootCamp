{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# ML Monitoring Fundamentals"
      ],
      "metadata": {
        "id": "A-s2CcWxkqZJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Setup\n",
        "\n",
        "Required to run this notebook\n",
        "- [Free WhyLabs Account](https://whylabs.ai/free)\n",
        "\n",
        "Reference to whylogs:\n",
        "- whylogs [GitHub](https://github.com/whylabs/whylogs/)\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "h5wtbbcE1tLa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Install whylogs\n",
        "!pip install 'whylogs[viz]'"
      ],
      "metadata": {
        "id": "Hg0cVqjbXnw6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "# 1. Data Drift, Model Drift, Performance\n"
      ],
      "metadata": {
        "id": "HWgoYjM3nVSa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import whylogs as why\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import datetime\n",
        "import os\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.datasets import load_iris\n",
        "\n",
        "pd.set_option(\"display.max_columns\", None)"
      ],
      "metadata": {
        "id": "hbVgO_PX6zrQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Train a Machine Learning Model"
      ],
      "metadata": {
        "id": "nDB3WgCT_QeJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_iris = load_iris(as_frame=True)\n",
        "\n",
        "print(list(df_iris.target_names))\n",
        "print(list(df_iris.feature_names))"
      ],
      "metadata": {
        "id": "201CjQ0d61Or"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train baseline Model\n",
        "# KNN Model\n",
        "from sklearn import neighbors\n",
        "knn = neighbors.KNeighborsClassifier(n_neighbors=5)\n",
        "\n",
        "# Create feature and target data varaible\n",
        "X, y = df_iris.data, df_iris.target\n",
        "\n",
        "#create train & test datasets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y,\n",
        "                                                    test_size=0.3,\n",
        "                                                    random_state=6,\n",
        "                                                    stratify=y)\n",
        "# Train model\n",
        "knn.fit(X_train, y_train)\n",
        "\n",
        "# Predict the labels on test data sset\n",
        "y_pred = knn.predict(X_test)\n",
        "\n",
        "# Print model accuracy\n",
        "knn.score(X_test, y_test)\n"
      ],
      "metadata": {
        "id": "qSDwodt_29si"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Import batches of data"
      ],
      "metadata": {
        "id": "gwCAnVjC7ws0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        " # Import data batches\n",
        "url = 'https://raw.githubusercontent.com/manifoldailearning/Complete-MLOps-BootCamp/main/ML-Monitoring-WhyLogs/datasets/iris_1_no_drift.csv'\n",
        "batch_data_1 = pd.read_csv(url)\n",
        "\n",
        "url2 = 'https://raw.githubusercontent.com/manifoldailearning/Complete-MLOps-BootCamp/main/ML-Monitoring-WhyLogs/datasets/iris_2_no_drift.csv'\n",
        "batch_data_2 = pd.read_csv(url2)\n",
        "\n",
        "url3 = 'https://raw.githubusercontent.com/manifoldailearning/Complete-MLOps-BootCamp/main/ML-Monitoring-WhyLogs/datasets/iris_3_no_drift.csv'\n",
        "batch_data_3 = pd.read_csv(url3)\n",
        "\n",
        "url4 = 'https://raw.githubusercontent.com/manifoldailearning/Complete-MLOps-BootCamp/main/ML-Monitoring-WhyLogs/datasets/iris_4_drift_0s.csv'\n",
        "batch_data_4 = pd.read_csv(url4)\n",
        "\n",
        "url5 = 'https://raw.githubusercontent.com/manifoldailearning/Complete-MLOps-BootCamp/main/ML-Monitoring-WhyLogs/datasets/iris_5_drift.csv'\n",
        "batch_data_5 = pd.read_csv(url5)\n",
        "\n",
        "url6 = 'https://raw.githubusercontent.com/manifoldailearning/Complete-MLOps-BootCamp/main/ML-Monitoring-WhyLogs/datasets/iris_6_drift.csv'\n",
        "batch_data_6 = pd.read_csv(url6)\n",
        "\n",
        "url7 = 'https://raw.githubusercontent.com/manifoldailearning/Complete-MLOps-BootCamp/main/ML-Monitoring-WhyLogs/datasets/iris_7_no_drift.csv'\n",
        "batch_data_7 = pd.read_csv(url7)\n",
        "\n",
        "# iris feature names\n",
        "feature_names = ['sepal length (cm)', 'sepal width (cm)','petal length (cm)','petal width (cm)']\n",
        "\n",
        "# separate targets\n",
        "X_batch_1 = batch_data_1[feature_names]\n",
        "X_batch_2 = batch_data_2[feature_names]\n",
        "X_batch_3 = batch_data_3[feature_names]\n",
        "X_batch_4 = batch_data_4[feature_names]\n",
        "X_batch_5 = batch_data_5[feature_names]\n",
        "X_batch_6 = batch_data_6[feature_names]\n",
        "X_batch_7 = batch_data_7[feature_names]\n",
        "\n",
        "y_batch_1 = batch_data_1['target']\n",
        "y_batch_2 = batch_data_2['target']\n",
        "y_batch_3 = batch_data_3['target']\n",
        "y_batch_4 = batch_data_4['target']\n",
        "y_batch_5 = batch_data_5['target']\n",
        "y_batch_6 = batch_data_6['target']\n",
        "y_batch_7 = batch_data_7['target']\n",
        "\n",
        "\n",
        "\n",
        "dfs = [X_batch_1, X_batch_4, X_batch_5, X_batch_6, X_batch_2, X_batch_3, X_batch_7]\n",
        "\n",
        "df_target = [y_batch_1, y_batch_4, y_batch_5, y_batch_6, y_batch_2, y_batch_3, y_batch_7]\n"
      ],
      "metadata": {
        "id": "b3hFOYP9l5MT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_batch_1"
      ],
      "metadata": {
        "id": "Nbb5uJAIn-TI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dfs[0].head()"
      ],
      "metadata": {
        "id": "QMINlHv9_y7X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Create a log with whylogs\n",
        "\n",
        "whylogs is an open source library for logging any kind of data. With whylogs, users are able to generate summaries of their datasets (called whylogs profiles) which they can use to:\n",
        "\n",
        "- Track changes in their dataset\n",
        "- Create data constraints to know whether their data looks the way it should\n",
        "- Quickly visualize key summary statistics about their datasets\n",
        "\n",
        "\n",
        "![](https://user-images.githubusercontent.com/7946482/171062942-01c420f2-7768-4b7c-88b5-e3f291e1b7d8.png)\n",
        "\n",
        "profiles generated with whylogs are:\n",
        "- Efficient\n",
        "- Customizable\n",
        "- Mergeable\n"
      ],
      "metadata": {
        "id": "D6wxQfvU7tsG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# create profile\n",
        "profile1 = why.log(X_batch_1)\n",
        "\n",
        "profile_view1 = profile1.view()\n",
        "profile_view1.to_pandas()"
      ],
      "metadata": {
        "id": "qT5MP_YATed2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Writing profiles to WhyLabs\n",
        "\n",
        "We're going start with an example of using profiles with the WhyLabs Observatory.\n",
        "\n",
        "We'll explore using whylogs for data validation & drift visualization after this!\n"
      ],
      "metadata": {
        "id": "VBqRX873TxoY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Get WhyLabs access tokens [expand]\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "4sWLrpTd-S7e"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Before integrate our data into WhyLabs we need three things:\n",
        "- WhyLabs API Key\n",
        "- WhyLabs Org-ID\n",
        "- Project-ID\n",
        "\n",
        "\n",
        "The easiest way to get the API token & ord-id:\n",
        "\n",
        "`Menu -> Settings -> Access Tokens`\n",
        "\n",
        "![](https://github.com/sagecodes/workshop-images/blob/master/access_token_org.png?raw=true)\n"
      ],
      "metadata": {
        "id": "fHuVMRyP-ibY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Sending profiles"
      ],
      "metadata": {
        "id": "y91-Gk8i-S_a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# set authentication & project keys\n",
        "os.environ[\"WHYLABS_DEFAULT_ORG_ID\"] = 'org-rdPzFz'\n",
        "os.environ[\"WHYLABS_API_KEY\"] = 'mH7YHZoCXk.FTQJZRgLvSh6uLuit3bDrMoNlGgu9OZubpEdGvq0nzbKCN7SI2INa:org-rdPzFz'\n",
        "os.environ[\"WHYLABS_DEFAULT_DATASET_ID\"] = 'model-3'"
      ],
      "metadata": {
        "id": "NKoMrJuU7Qoy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from whylogs.api.writer.whylabs import WhyLabsWriter"
      ],
      "metadata": {
        "id": "MgHBpPlsUkxS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Single Profile\n",
        "writer = WhyLabsWriter()\n",
        "profile= why.log(X_batch_1)\n",
        "writer.write(file=profile.view())"
      ],
      "metadata": {
        "id": "NZz5q5iTCnmX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Write multiple profiles with different dates to backfill"
      ],
      "metadata": {
        "id": "OaoYzdSqDBmx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# initialize writer\n",
        "writer = WhyLabsWriter()\n",
        "\n",
        "# back fill 1 day per batch\n",
        "for i, df in enumerate(dfs):\n",
        "\n",
        "    # walking backwards. Each dataset has to map to a date to show up as a different batch in WhyLabs\n",
        "    dt = datetime.datetime.now(tz=datetime.timezone.utc) - datetime.timedelta(days=i)\n",
        "\n",
        "    # create profile for each batch of data\n",
        "    profile = why.log(df).profile()\n",
        "\n",
        "    # set the dataset timestamp for the profile\n",
        "    profile.set_dataset_timestamp(dt)\n",
        "    # write the profile to the WhyLabs platform\n",
        "    writer.write(file=profile.view())"
      ],
      "metadata": {
        "id": "PUPdYFR_7Qra"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Reference Profile"
      ],
      "metadata": {
        "id": "-EhY4gaaMd_9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ref_profile = why.log(df_iris.data).profile()\n",
        "writer = WhyLabsWriter().option(reference_profile_name=\"iris_training_profile\")\n",
        "writer.write(file=ref_profile.view())"
      ],
      "metadata": {
        "id": "HXs5QrrvqaNY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Logging output"
      ],
      "metadata": {
        "id": "3DR_y0YDCL6n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Get predictions with model & append to df\n",
        "pred_dfs = dfs\n",
        "\n",
        "class_names = ['setosa', 'versicolor', 'virginica']\n",
        "\n",
        "for i, df in enumerate(pred_dfs):\n",
        "    y_pred = knn.predict(df)\n",
        "    y_prob = knn.predict_proba(df)\n",
        "    pred_scores = []\n",
        "    pred_classes = []\n",
        "\n",
        "    for pred in y_pred:\n",
        "      pred_classes.append(class_names[pred])\n",
        "    df['cls_output'] = pred_classes\n",
        "    for prob in y_prob:\n",
        "      pred_scores.append(max(prob))\n",
        "    df['prob_output'] = pred_scores\n",
        "    # print(pred_scores)"
      ],
      "metadata": {
        "id": "f4W-fVNaIDfF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pred_dfs[-1]"
      ],
      "metadata": {
        "id": "1LzG99NcIMsW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "writer = WhyLabsWriter()\n",
        "\n",
        "for i, df in enumerate(pred_dfs):\n",
        "\n",
        "    out_df = df[['cls_output', 'prob_output']].copy()\n",
        "   # walking backwards. Each dataset has to map to a date to show up as a different batch in WhyLabs\n",
        "    dt = datetime.datetime.now(tz=datetime.timezone.utc) - datetime.timedelta(days=i)\n",
        "    profile = why.log(out_df).profile()\n",
        "\n",
        "    # set the dataset timestamp for the profile\n",
        "    profile.set_dataset_timestamp(dt)\n",
        "    #write the profile to the WhyLabs platform\n",
        "    writer.write(file=profile.view())"
      ],
      "metadata": {
        "id": "cbV_rmoS9oGe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Log performance\n",
        "\n",
        "Instead of just logging outputs, if we have ground truth data we can also monitor performance metrics overtime.\n",
        "\n",
        "\n",
        "Classification:\n",
        "\n",
        "Regression:\n"
      ],
      "metadata": {
        "id": "tONc51OQVuPD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pred_dfs[-1]"
      ],
      "metadata": {
        "id": "ABKjCIJh9oNe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Append ground truth data to dataframe\n",
        "for i, df in enumerate(pred_dfs):\n",
        "    df['ground_truth'] = df_target[i]"
      ],
      "metadata": {
        "id": "SV17fadTNbSG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pred_dfs[0]"
      ],
      "metadata": {
        "id": "FDVEon3oUR8v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Log performance\n",
        "\n",
        "for i, df in enumerate(pred_dfs):\n",
        "\n",
        "  results = why.log_classification_metrics(\n",
        "          df,\n",
        "          target_column = \"ground_truth\",\n",
        "          prediction_column = \"cls_output\",\n",
        "          score_column=\"prob_output\"\n",
        "      )\n",
        "   # walking backwards. Each dataset has to map to a date to show up as a different batch in WhyLabs\n",
        "  dt = datetime.datetime.now(tz=datetime.timezone.utc) - datetime.timedelta(days=i)\n",
        "\n",
        "  profile = results.profile()\n",
        "  profile.set_dataset_timestamp(dt)\n",
        "\n",
        "  results.writer(\"whylabs\").write()"
      ],
      "metadata": {
        "id": "sgbPtZ-a298g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. Monitoring for Bias & Fairness with Tracing & Explainability\n",
        "\n"
      ],
      "metadata": {
        "id": "jRDctvTYW7VT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Imports\n",
        "import whylogs as why\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import datetime\n",
        "import os\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.datasets import load_iris\n",
        "\n",
        "pd.set_option(\"display.max_columns\", None)"
      ],
      "metadata": {
        "id": "z2aYxyLxt8JL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load iris data as dataframe(df)\n",
        "df_iris = load_iris(as_frame=True)\n",
        "\n",
        "print(list(df_iris.target_names))\n",
        "print(list(df_iris.feature_names))"
      ],
      "metadata": {
        "id": "O_7sSMA1ORDw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Train a Machine Learning Model (quickly)"
      ],
      "metadata": {
        "id": "JFiVd4ZhxqZ5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn import neighbors\n",
        "knn = neighbors.KNeighborsClassifier(n_neighbors=5)\n",
        "\n",
        "X, y = df_iris.data, df_iris.target\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y,\n",
        "                                                    test_size=0.3,\n",
        "                                                    random_state=42,\n",
        "                                                    stratify=y)\n",
        "# Train model\n",
        "knn.fit(X_train, y_train)\n",
        "\n",
        "# Predict the labels on test data sset\n",
        "y_pred = knn.predict(X_test)\n",
        "\n",
        "# Print model accuracy\n",
        "knn.score(X_test, y_test)"
      ],
      "metadata": {
        "id": "Xj-UtdLTORGM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Import data batches"
      ],
      "metadata": {
        "id": "uwWYPxFBw11o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        " # Import data batches\n",
        "url = 'https://raw.githubusercontent.com/manifoldailearning/Complete-MLOps-BootCamp/main/ML-Monitoring-WhyLogs/datasets/iris_8_statefl_1.csv'\n",
        "batch_data_1 = pd.read_csv(url)\n",
        "\n",
        "url2 = 'https://raw.githubusercontent.com/manifoldailearning/Complete-MLOps-BootCamp/main/ML-Monitoring-WhyLogs/datasets/iris_9_statefl_1.csv'\n",
        "batch_data_2 = pd.read_csv(url2)\n",
        "\n",
        "url3 = 'https://raw.githubusercontent.com/manifoldailearning/Complete-MLOps-BootCamp/main/ML-Monitoring-WhyLogs/datasets/iris_10_statefl_1.csv'\n",
        "batch_data_3 = pd.read_csv(url3)\n",
        "\n",
        "url4 = 'https://raw.githubusercontent.com/manifoldailearning/Complete-MLOps-BootCamp/main/ML-Monitoring-WhyLogs/datasets/iris_11_statefl_1.csv'\n",
        "batch_data_4 = pd.read_csv(url4)\n",
        "\n",
        "url5 = 'https://raw.githubusercontent.com/manifoldailearning/Complete-MLOps-BootCamp/main/ML-Monitoring-WhyLogs/datasets/iris_12_statefl_1.csv'\n",
        "batch_data_5 = pd.read_csv(url5)\n",
        "\n",
        "url6 = 'https://raw.githubusercontent.com/manifoldailearning/Complete-MLOps-BootCamp/main/ML-Monitoring-WhyLogs/datasets/iris_13_statefl_1.csv'\n",
        "batch_data_6 = pd.read_csv(url6)\n",
        "\n",
        "url7 = 'https://raw.githubusercontent.com/manifoldailearning/Complete-MLOps-BootCamp/main/ML-Monitoring-WhyLogs/datasets/iris_14_statefl_1.csv'\n",
        "batch_data_7 = pd.read_csv(url7)\n",
        "\n",
        "# iris feature names\n",
        "feature_names = ['sepal length (cm)', 'sepal width (cm)','petal length (cm)','petal width (cm)', 'state']\n",
        "\n",
        "# separate targets\n",
        "X_batch_1 = batch_data_1[feature_names]\n",
        "X_batch_2 = batch_data_2[feature_names]\n",
        "X_batch_3 = batch_data_3[feature_names]\n",
        "X_batch_4 = batch_data_4[feature_names]\n",
        "X_batch_5 = batch_data_5[feature_names]\n",
        "X_batch_6 = batch_data_6[feature_names]\n",
        "X_batch_7 = batch_data_7[feature_names]\n",
        "\n",
        "# We'll save the target values for later!\n",
        "y_batch_1 = batch_data_1['target']\n",
        "y_batch_2 = batch_data_2['target']\n",
        "y_batch_3 = batch_data_3['target']\n",
        "y_batch_4 = batch_data_4['target']\n",
        "y_batch_5 = batch_data_5['target']\n",
        "y_batch_6 = batch_data_6['target']\n",
        "y_batch_7 = batch_data_7['target']\n",
        "\n",
        "\n",
        "# create list of our batches\n",
        "dfs = [X_batch_1, X_batch_4, X_batch_5, X_batch_6, X_batch_2, X_batch_3, X_batch_7]\n",
        "\n",
        "df_target = [y_batch_1, y_batch_4, y_batch_5, y_batch_6, y_batch_2, y_batch_3, y_batch_7]\n"
      ],
      "metadata": {
        "id": "7oW7q0nqqpcE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dfs[0].head()"
      ],
      "metadata": {
        "id": "8cLAQ0MLORKc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "## Creating profiles with whylogs\n",
        "\n",
        "\n",
        "Profiles generated with whylogs are:\n",
        "\n",
        "- Secure\n",
        "- Efficient\n",
        "- Customizable\n",
        "- Mergeable"
      ],
      "metadata": {
        "id": "FGs12cQFtWtz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# create profile\n",
        "profile1 = why.log(X_batch_1)\n",
        "\n",
        "profile_view1 = profile1.view()\n",
        "profile_view1.to_pandas()"
      ],
      "metadata": {
        "id": "6DmNVWvHORO2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# set authentication & project keys\n",
        "# os.environ[\"WHYLABS_DEFAULT_ORG_ID\"] = 'ORGID'\n",
        "# os.environ[\"WHYLABS_API_KEY\"] = 'APIKEY'\n",
        "os.environ[\"WHYLABS_DEFAULT_DATASET_ID\"] = 'MODELID'"
      ],
      "metadata": {
        "id": "uLMjJqPlORRM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Create dataframe with model predictions"
      ],
      "metadata": {
        "id": "g3NivdEh0yzi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Get predictions with model & append to df\n",
        "pred_dfs = dfs\n",
        "\n",
        "class_names = ['setosa', 'versicolor', 'virginica']\n",
        "\n",
        "for i, df in enumerate(pred_dfs):\n",
        "    y_pred = knn.predict(df.iloc[:, :4])\n",
        "    y_prob = knn.predict_proba(df.iloc[:, :4])\n",
        "    pred_scores = []\n",
        "    pred_classes = []\n",
        "\n",
        "    for pred in y_pred:\n",
        "      pred_classes.append(class_names[pred])\n",
        "    df['cls_output'] = pred_classes\n",
        "    for prob in y_prob:\n",
        "      pred_scores.append(max(prob))\n",
        "    df['prob_output'] = pred_scores"
      ],
      "metadata": {
        "id": "k5BOIO5-Ot7L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pred_dfs[-1]"
      ],
      "metadata": {
        "id": "HeQiByHVOt9h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Backfilling data in WhyLabs"
      ],
      "metadata": {
        "id": "HzDBFCKP1KT7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from whylogs.core.schema import DatasetSchema\n",
        "from whylogs.core.segmentation_partition import segment_on_column"
      ],
      "metadata": {
        "id": "4bScxUu6mGX1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# back fill 1 day per batch\n",
        "for i, df in enumerate(pred_dfs):\n",
        "    # walking backwards. Each dataset has to map to a date to show up as a different batch in WhyLabs\n",
        "    dt = datetime.datetime.now(tz=datetime.timezone.utc) - datetime.timedelta(days=i)\n",
        "\n",
        "    # create profile for each batch of data\n",
        "    profile = why.log(df, schema=DatasetSchema(segments=segment_on_column(\"state\")))\n",
        "\n",
        "    # set the dataset timestamp for the profile\n",
        "    profile.set_dataset_timestamp(dt)\n",
        "    # write the profile to the WhyLabs platform\n",
        "    profile.writer(\"whylabs\").write()"
      ],
      "metadata": {
        "id": "Tym3Orxluxiu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Learn more about segmentation in whylogs\n",
        "- [Intro to Segmentation with whylogs](https://github.com/whylabs/whylogs/blob/mainline/python/examples/advanced/Segments.ipynb)"
      ],
      "metadata": {
        "id": "nl1ibhchyQdS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create reference profile\n",
        "ref_profile = why.log(df_iris.data).profile()\n",
        "writer = WhyLabsWriter().option(reference_profile_name=\"iris_training_profile\")\n",
        "writer.write(file=ref_profile.view())"
      ],
      "metadata": {
        "id": "VXwHoHswQ106"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Classification Performance Metrics"
      ],
      "metadata": {
        "id": "r9VnBBT5u0TR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Append ground truth data to dataframe\n",
        "for i, df in enumerate(pred_dfs):\n",
        "    df['ground_truth'] = df_target[i]"
      ],
      "metadata": {
        "id": "GEo0H6qjO2sR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pred_dfs[0]"
      ],
      "metadata": {
        "id": "pdZ2se8aOt_7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from whylogs import log_classification_metrics\n",
        "# from whylogs.core.schema import DatasetSchema\n",
        "# from whylogs.core.segmentation_partition import segment_on_column"
      ],
      "metadata": {
        "id": "c7vyAeDLU6OE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i, df in enumerate(pred_dfs):\n",
        "\n",
        "  segmented_classification_results = log_classification_metrics(\n",
        "    df,\n",
        "    target_column = \"ground_truth\",\n",
        "    prediction_column = \"cls_output\",\n",
        "    schema = DatasetSchema(segments=segment_on_column(\"state\"))\n",
        "  )\n",
        "   # walking backwards. Each dataset has to map to a date to show up as a different batch in WhyLabs\n",
        "  dt = datetime.datetime.now(tz=datetime.timezone.utc) - datetime.timedelta(days=i)\n",
        "\n",
        "  # profile = segmented_classification_results.profile()\n",
        "  segmented_classification_results.set_dataset_timestamp(dt)\n",
        "\n",
        "  segmented_classification_results.writer(\"whylabs\").write()"
      ],
      "metadata": {
        "id": "SyS4i2ZsO-OT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "QWsPj1MblwEU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Feature importance\n",
        "\n",
        "Learn more about SHAP\n",
        "https://github.com/slundberg/shap"
      ],
      "metadata": {
        "id": "V8VKKZYil1Ma"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install shap"
      ],
      "metadata": {
        "id": "Q2Y1Vx8vlwN6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import shap"
      ],
      "metadata": {
        "id": "Ea465we2lwS2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "explainer = shap.Explainer(knn.predict, X_train)"
      ],
      "metadata": {
        "id": "BkzneIbrmGwp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "shap_values = explainer(X_test)"
      ],
      "metadata": {
        "id": "sCo9pB8tmGwy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "shap.summary_plot(shap_values, X_test, plot_type=\"bar\")"
      ],
      "metadata": {
        "id": "KMZL1U-YmGwy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get global featue importance\n",
        "shap_feature_importance = np.mean(np.abs(shap_values.values), axis=0)"
      ],
      "metadata": {
        "id": "JyZyyVLwmGwy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create dict with feature importance\n",
        "shap_feature_importance_dict = dict(zip(X_train.columns.tolist(), shap_feature_importance.tolist()))\n",
        "feature_importance_dict = {k: v for k, v in sorted(shap_feature_importance_dict.items(),\n",
        "                                                   key=lambda item: item[1], reverse=True)}\n"
      ],
      "metadata": {
        "id": "ekvja7mpmGwy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(feature_importance_dict)"
      ],
      "metadata": {
        "id": "Kuqo8POWmGwz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Write values to WhyLabs\n",
        "from whylogs.core.feature_weights import FeatureWeights\n",
        "from whylogs.api.writer.whylabs import WhyLabsWriter\n",
        "\n",
        "feature_weights = FeatureWeights(shap_feature_importance_dict)\n",
        "result = feature_weights.writer(\"whylabs\").write()\n",
        "\n",
        "result"
      ],
      "metadata": {
        "id": "UBJ4AcGamGwz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3. Open-source data & ML monitoring with whylogs"
      ],
      "metadata": {
        "id": "rJtwW4Zuo3ib"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Using data drift reports with whylogs in a Python environment\n",
        "\n",
        "![](https://whylabs.ai/_next/image?url=https%3A%2F%2Fcontent.whylabs.ai%2Fcontent%2Fimages%2F2022%2F06%2FTDSImage3.jpeg&w=3120&q=75)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "JbyKcuP7ozSe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# creat profiles of batches\n",
        "\n",
        "profile_view1 = why.log(X_batch_1).view()\n",
        "profile_view1 = why.log(X_batch_1).view()\n",
        "profile_view2 = why.log(X_batch_2).view()\n",
        "profile_view3 = why.log(X_batch_3).view()\n",
        "profile_view4 = why.log(batch_data_4).view()\n",
        "profile_view5 = why.log(batch_data_5).view()\n",
        "profile_view6 = why.log(batch_data_6).view()\n",
        "profile_view7 = why.log(X_batch_7).view()\n",
        "# profile_view8 = why.log(batch_data_8).view()"
      ],
      "metadata": {
        "id": "lcUDBSE3ozSe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Data Drift with whylogs\n",
        "from whylogs.viz import NotebookProfileVisualizer\n",
        "\n",
        "visualization = NotebookProfileVisualizer()\n",
        "visualization.set_profiles(target_profile_view=profile_view1, reference_profile_view=profile_view2)"
      ],
      "metadata": {
        "id": "0nnuzNkPozSf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "visualization.summary_drift_report()"
      ],
      "metadata": {
        "id": "ZM1eNsJEozSf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "visualization.double_histogram(feature_name=\"petal width (cm)\")\n"
      ],
      "metadata": {
        "id": "yj_xxvbuozSf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "visualization.double_histogram(feature_name=\"petal length (cm)\")\n"
      ],
      "metadata": {
        "id": "t4xMdIi7ozSf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from whylogs.viz.drift.column_drift_algorithms import calculate_drift_scores\n",
        "\n",
        "scores = calculate_drift_scores(target_view=profile_view1, reference_view=profile_view2, with_thresholds = True)\n",
        "\n",
        "scores"
      ],
      "metadata": {
        "id": "RoMMefrKozSf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Compare Another profiles:\n",
        "\n",
        "from whylogs.viz import NotebookProfileVisualizer\n",
        "\n",
        "visualization = NotebookProfileVisualizer()\n",
        "visualization.set_profiles(target_profile_view=profile_view1, reference_profile_view=profile_view3)"
      ],
      "metadata": {
        "id": "2RtmXCzPozSg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "visualization.summary_drift_report()"
      ],
      "metadata": {
        "id": "iH9wevvBozSg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "visualization.double_histogram(feature_name=\"petal length (cm)\")\n"
      ],
      "metadata": {
        "id": "QKbJgfmrozSg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "visualization.double_histogram(feature_name=\"petal width (cm)\")\n"
      ],
      "metadata": {
        "id": "heD8sSqEozSg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from whylogs.viz.drift.column_drift_algorithms import calculate_drift_scores\n",
        "\n",
        "scores = calculate_drift_scores(target_view=profile_view1, reference_view=profile_view6, with_thresholds = True)\n",
        "\n",
        "scores"
      ],
      "metadata": {
        "id": "sqmoLLBpozSg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Learn more about using data drift reports with whylogs\n",
        "- [Drift Algorithm Configuration](https://github.com/whylabs/whylogs/blob/mainline/python/examples/advanced/Drift_Algorithm_Configuration.ipynb)\n",
        "\n"
      ],
      "metadata": {
        "id": "94qjzowPozSh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data validation with constraints in whylogs\n",
        "\n",
        "\n",
        "Data quality validation ensures data is structured and falls in the range expected for our data pipelines or applications. When collecting or using data it’s important to verify the quality to avoid unwanted machine learning behavior in production, such as errors or faulty prediction results.\n",
        "\n",
        "For example, we may want to ensure our data doesn’t contain any empty or negative values before moving it along in the pipeline if our model does not expect those values."
      ],
      "metadata": {
        "id": "dWYdnpAYozSh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Data Quality Validation whylogs\n",
        "\n",
        "from whylogs.core.constraints import (Constraints,\n",
        "                                     ConstraintsBuilder,\n",
        "                                     MetricsSelector,\n",
        "                                     MetricConstraint)"
      ],
      "metadata": {
        "id": "pCaUaR09ozSh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Using Constraints for Data Quality Validation\n",
        "\n",
        "def validate_features(profile_view, verbose=False):\n",
        "\n",
        "  builder = ConstraintsBuilder(profile_view)\n",
        "\n",
        "  # Define a constraint for validating data\n",
        "  builder.add_constraint(MetricConstraint(\n",
        "    name=\"petal length > 0 and < 15\",\n",
        "    condition=lambda x: x.min > 0 and x.max < 15,\n",
        "    metric_selector=MetricsSelector(metric_name='distribution',\n",
        "                                    column_name='petal length (cm)')\n",
        "  ))\n",
        "\n",
        "  builder.add_constraint(MetricConstraint(\n",
        "    name=\"petal width > 0 and < 15\",\n",
        "    condition=lambda x: x.min > 0 and x.max < 15,\n",
        "    metric_selector=MetricsSelector(metric_name='distribution',\n",
        "                                    column_name='petal width (cm)')\n",
        "  ))\n",
        "\n",
        "  builder.add_constraint(MetricConstraint(\n",
        "    name=\"sepal length > 0 and < 15\",\n",
        "    condition=lambda x: x.min > 0 and x.max < 15 ,\n",
        "    metric_selector=MetricsSelector(metric_name='distribution',\n",
        "                                    column_name='sepal length (cm)')\n",
        "  ))\n",
        "\n",
        "  builder.add_constraint(MetricConstraint(\n",
        "    name=\"sepal width > 0 and < 15\",\n",
        "    condition=lambda x: x.min > 0 and x.max < 15,\n",
        "    metric_selector=MetricsSelector(metric_name='distribution',\n",
        "                                    column_name='sepal width (cm)')\n",
        "  ))\n",
        "\n",
        "  # Build the constraints and return the report\n",
        "  constraints: Constraints = builder.build()\n",
        "\n",
        "  if verbose:\n",
        "    print(constraints.report())\n",
        "\n",
        "  # return constraints.report()\n",
        "  return constraints\n"
      ],
      "metadata": {
        "id": "ARysjMvoozSh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "const = validate_features(profile_view2, True)"
      ],
      "metadata": {
        "id": "HrLKsA2rozSh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from whylogs.viz import NotebookProfileVisualizer\n",
        "visualization = NotebookProfileVisualizer()\n",
        "visualization.constraints_report(const, cell_height=300)"
      ],
      "metadata": {
        "id": "qbrJKm6JozSi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# check all constraints for passing:\n",
        "constraints_valid = const.validate()\n",
        "print(constraints_valid)"
      ],
      "metadata": {
        "id": "11NSc6g8ozSi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "const = validate_features(profile_view4, True)"
      ],
      "metadata": {
        "id": "SsuWMedTozSi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "visualization = NotebookProfileVisualizer()\n",
        "visualization.constraints_report(const, cell_height=300)"
      ],
      "metadata": {
        "id": "PRaqg6RKozSi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# check all constraints for passing:\n",
        "constraints_valid = const.validate()\n",
        "print(constraints_valid)"
      ],
      "metadata": {
        "id": "u2F7cWProzSi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "profile_view4.to_pandas()"
      ],
      "metadata": {
        "id": "H4CR3xIOozSj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Leran more about performing data validation with whylogs\n",
        "- [Data Validation with Metric Constraints](https://github.com/whylabs/whylogs/blob/mainline/python/examples/advanced/Metric_Constraints.ipynb)\n"
      ],
      "metadata": {
        "id": "ANfGcCORozSj"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "fEc0gKP1W62h"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}